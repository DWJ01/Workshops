# Welcome to Noel's Workshop Pages

This is where the descriptions of the workshops will be uploaded

# Spring 2018 Workshops

## Kickstarters

**GitHub**

_Feb 05 11:00 AM_

Kickstart your software engineer career with a star profile on GitHub. Come to this workshop to learn the basics of git versioning, as well as to learn some tips on building your portfolio. You will be working in groups to simulate versioning problems. In this workshop, you will learn how to create a repository, start and manage branches, merge pull requests, write a basic markdown file, and how to be social on GitHub!

## Tensorflow Series

**Tensorflow: The Basics**

_Mar 12 3:30 PM_

Tensorflow is crucial in building neural networks faster. However, the basics of Tensorflow may be confusing as building, training, testing models arenâ€™t that straightforward. Come to this session to learn about placeholders, variables, graphs, and sessions. In the end, we will build a rudimentary regression model to put into practice your knowledge of Tensorflow. This workshop is the first of the Tensorflow workshop series in which Deep Neural Networks and Recurrent Neural Networks will be explored. The Basics workshop lays down the foundation for the subsequent two workshops.

**Tensorflow: Wide & Deep Learning**

_Mar 14 3:30 PM_

In this workshop, you will learn how to create a Wide and Deep Neural Network. With a Wide and Deep Neural Network, you will be able to perform classification and regression tasks. The skills you will learn through this workshop include the following. You will be able to create feature columns (numerical, categorical with hash bucket, bucketized) in Tensorflow, cross these columns if needed for the Wide Model, embed sparse feature columns into the Deep Model and combine them for a Wide & Deep Model. The workshop will provide a sample dataset that you will use to train your model. If you are interested in how Wide & Deep Learning works, read this [research paper](https://arxiv.org/abs/1606.07792). 

**Tensorflow: Recurrent Neural Networks**

_Mar 19 3:30 PM_

This is a more advanced Tensorflow workshop. In the first 15 minutes, we will cover the building blocks of Recurrent Neural Networks (RNN). RNNs are typically used for time-series data prediction, as well as language modeling. The core feature of the model is that it feeds in the output from the previous state among the inputs to the new state, thus creating some degree of time-bound (or syntax relational) dependency. We will get started with a time-series dataset, which we will use to train our model to predict future steps. If you are interested in how RNNs work, read this [excellent guide](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).

## Web Data Collection Series

**Using Yelp API**

_Time TBD_

**Data Scraping**

_Time TBD_




